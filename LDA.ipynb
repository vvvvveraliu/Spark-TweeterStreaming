{"cells":[{"cell_type":"code","execution_count":35,"metadata":{"id":"UjlYUoo3nK-9"},"outputs":[],"source":["from pyspark import SparkConf, SparkContext,SQLContext  \n","from pyspark.sql import SparkSession   \n","from pyspark.ml.feature import Word2Vec,CountVectorizer  \n","from pyspark.ml.clustering import LDA, LDAModel  \n","from pyspark.sql.functions import col, udf  \n","from pyspark.sql.types import IntegerType,ArrayType,StringType  \n","import pylab as pl  "]},{"cell_type":"code","execution_count":36,"metadata":{"id":"y4jjf6wWnU3D"},"outputs":[],"source":["def to_word(termIndices):\n","  words = []  \n","  for termID in termIndices:\n","    words.append(vocab_broadcast.value[termID])      \n","  return words"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"RbEMpBH_nrPy"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|               words|\n","+--------------------+\n","|[I, absolutely, A...|\n","|[Java, Vs, Python...|\n","|[voulu, un, grec,...|\n","|[Pareil, Il, pris...|\n","|[Music, Academy, ...|\n","|[Tarps,, tents,, ...|\n","|[voulu, un, grec,...|\n","|[We, drive, effic...|\n","|[Check, out, my, ...|\n","|[Hey,, nice, bone...|\n","|[lembro, como, so...|\n","|[WHO, WITH, A, DE...|\n","|[@Tina69911364, @...|\n","|[alguem, cria, um...|\n","|[@Neptvn08, Comme...|\n","|[une, dinguerie, ...|\n","|[Y, a, une, gross...|\n","|[Je, te, cache, p...|\n","|[@JAPANFESS, seta...|\n","|[Femme, rechercha...|\n","+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql.functions import split\n","\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Python Spark SQL basic example\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()\n","\n","spark_df = spark.read.options(inferschema='true') \\\n","                .csv(\"gs://6893_bda/hw2/stream_data.csv\")\n","spark_df=spark_df.select(split(col(\"_c0\"),\" \") \\\n","                .alias(\"words\")) \\\n","                .drop(\"_c0\")\n","\n","spark_df.show()"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------------------------------------------------------------------------------+-------------+\n","|words                                                                                                                             |features     |\n","+----------------------------------------------------------------------------------------------------------------------------------+-------------+\n","|[I, absolutely, ADORED, ETERNALS,, but, I, recognize, not, cup, of, Marvel, tea., This, might, not, make, a, whole, lot, of]      |(3,[0],[1.0])|\n","|[Java, Vs, Python, For, Data, Science, #cybersecurity, #devops, #100DaysOfCode, #ai, #codenewbie, #machinelearning, #DEVCommunity]|(3,[],[])    |\n","|[voulu, un, grec, puis, suis, dit, non, manger, la, maison, et, jsuis, donc]                                                      |(3,[],[])    |\n","|[Pareil, Il, pris, de, ma, poche, et, quand, je, lui, prends, des, mains, il, me, dit]                                            |(3,[2],[1.0])|\n","|[Music, Academy, Blog, Post, movie, was, a, collaboration, between, a, very, famous, singer, in, our, country,, EXO]              |(3,[0],[2.0])|\n","|[Tarps,, tents,, and, medical, examiner, all, indicate, deceased., seen, this, movie, before.]                                    |(3,[],[])    |\n","|[voulu, un, grec, puis, suis, dit, non, manger, la, maison, et, jsuis, donc]                                                      |(3,[],[])    |\n","|[We, drive, efficiencies, in, insurance, Claim, Automation,, frictionless, payments,, efficient, risk, management, #Otonomi]      |(3,[],[])    |\n","|[Check, out, my, Gig, on, I, will, design, #creative, #travel, #hotel, #tour, #resort, #adventure, #photography, #unique, logo]   |(3,[],[])    |\n","|[Hey,, nice, bones, you, got, there!, Now, live, with, AI, The, Somnium, #ENVtuber, #Vtuber]                                      |(3,[],[])    |\n","|[lembro, como, sofri, no, hiatus, do, izone, pela, e, ainda, mais, como, fiquei, ansiosa, no, dia, q, fiesta]                     |(3,[],[])    |\n","|[WHO, WITH, A, DEEP, THROAT, FOR, MY, I, AM, VERY, HOT, DALE, #, AND, I, SENT, YOU, THE, VIDEO, MASTURBANDOME, TO, THE]           |(3,[],[])    |\n","|[@Tina69911364, @AstaMuratti, @7lostinthewoods, From, the, movie, Michael, Collins, The, Foggy, Dew, Fog]                         |(3,[1],[1.0])|\n","|[alguem, cria, um, apelido, pra, maria, luiza, ai, nao, aguento, mais, os, mesmos]                                                |(3,[],[])    |\n","|[@Neptvn08, Comment, trop, bien, cette, reprise, de, saison, envie, de, parler, que, de, mdrrr]                                   |(3,[2],[3.0])|\n","|[une, dinguerie, de, fou, furieux, vous, faire, gagner,, valeur, du, lot, Pour, participer, au, concours, ce, tweet]              |(3,[2],[1.0])|\n","|[Y, a, une, grosse, mouvance, sur, TikTok/Reels, avec, moults, meufs/mecs, en, chemise, blanche,]                                 |(3,[0],[1.0])|\n","|[Je, te, cache, pas, que, de, nombreuses, fois, block, et, avec, leurs, vils, paroles]                                            |(3,[2],[1.0])|\n","|[@JAPANFESS, setauku, sih, LA, Tokrev,, movie, idk, sih, blm, tau, pastinya]                                                      |(3,[],[])    |\n","|[Femme, recherchant, du, plaisir, avec, des, personnes, coquines., une, poitrine, naturelle., le, sexe]                           |(3,[],[])    |\n","+----------------------------------------------------------------------------------------------------------------------------------+-------------+\n","only showing top 20 rows\n","\n"]}],"source":["#CountVectorizer\n","\n","cv=CountVectorizer(inputCol=\"words\", \\\n","               outputCol=\"features\", \\\n","               vocabSize=3,minDF=6)\n","model=cv.fit(spark_df)\n","cvResult=model.transform(spark_df)\n","cvResult.show(truncate=False)\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["#train LDA model, cluster the documents into 10 topics \n","\n","lda = LDA(k=10, maxIter=100)\n","ldaModel=lda.fit(result)\n"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"ovzUq8JPow3S"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|topicDistribution                                                                                                                                                                                             |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[0.6005681603306324,0.0386782389613483,0.09000511094083564,0.03867847382487296,0.03867836980715218,0.03867848781002219,0.038678166703342405,0.038678112780249706,0.03867829452459278,0.038678584316951425]    |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.11726218196181631,0.0386782640911244,0.5733107453397492,0.03867851204170318,0.03867843661618515,0.038678523926319576,0.038678199249586834,0.03867817173643598,0.038678335405331686,0.038678629631747515]   |\n","|[0.7307156354073189,0.02607565155606007,0.060678600330138055,0.026075810153194358,0.02607573992000674,0.026075818989079465,0.026075603387898938,0.026075567164397292,0.02607568897642692,0.026075884115479418]|\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.11726233814785646,0.03867824923385412,0.5733106968312964,0.038678547622685695,0.038678386423786786,0.03867850924553682,0.03867821240688496,0.038678133549944385,0.03867829723312586,0.03867862930502845]   |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.05962616393549576,0.019667405492003784,0.7830340900616306,0.019667532070315793,0.019667504289237858,0.01966753941925469,0.019667372570298478,0.01966735688677542,0.019667442656334373,0.01966759261865325] |\n","|[0.11726218196181631,0.0386782640911244,0.5733107453397492,0.03867851204170318,0.03867843661618515,0.038678523926319576,0.038678199249586834,0.03867817173643598,0.038678335405331686,0.038678629631747515]   |\n","|[0.6005681603306324,0.0386782389613483,0.09000511094083564,0.03867847382487296,0.03867836980715218,0.03867848781002219,0.038678166703342405,0.038678112780249706,0.03867829452459278,0.038678584316951425]    |\n","|[0.11726218196181631,0.0386782640911244,0.5733107453397492,0.03867851204170318,0.03867843661618515,0.038678523926319576,0.038678199249586834,0.03867817173643598,0.038678335405331686,0.038678629631747515]   |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                                                                                                                                                     |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["transformed = ldaModel.transform(cvResult) \\\n","                    .select(\"topicDistribution\")  \n","#show the weight of every topic Distribution \n","transformed.show(truncate=False)  "]},{"cell_type":"code","execution_count":46,"metadata":{"id":"tz6D0Tllo5bs"},"outputs":[{"name":"stdout","output_type":"stream","text":["ll:  -1188.4912987714956\n","lp:  1.9612067636493327\n"]}],"source":["#The higher ll is, the lower lp is, the better model is.\n","ll = ldaModel.logLikelihood(cvResult)  \n","lp = ldaModel.logPerplexity(cvResult)\n","print(\"ll: \", ll)\n","print(\"lp: \", lp)"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"MQ_Ukzz4sS69"},"outputs":[{"name":"stdout","output_type":"stream","text":["Learned topics (as distributions over vocab of 3 words):\n","DenseMatrix([[23.39368276,  0.19560305,  0.18781267,  0.1991493 ,  0.19822299,\n","               0.20680644,  0.18875968,  0.1853626 ,  0.19743615,  0.20908859],\n","             [ 0.18039432,  0.17821403, 14.43101239,  0.21552116,  0.18505439,\n","               0.19326789,  0.19539444,  0.17922252,  0.17432955,  0.20810173],\n","             [ 0.17801635,  0.18708805, 14.42455494,  0.19929065,  0.2100472 ,\n","               0.20094358,  0.18850754,  0.19942027,  0.19639779,  0.20825067]])\n"]}],"source":["# Output topics. Each is a distribution over words (matching word count vectors)\n","print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())+ \" words):\")\n","topics = ldaModel.topicsMatrix()\n","print(topics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"6893_HW2PartII_LDA.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":1}
